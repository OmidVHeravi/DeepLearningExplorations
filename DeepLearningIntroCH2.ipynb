{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwhP0/H96bs5tzBdHSPFSD"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Efficient Computation"
      ],
      "metadata": {
        "id": "qlozvsnOO6c-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its very important to realize that deep learning research is much about mathemtical correctness, as it is about implementing it effectively on modern machines."
      ],
      "metadata": {
        "id": "_4pJbxOPfcWx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPUs, TPUs, and Batches"
      ],
      "metadata": {
        "id": "GS-k0e4dfZSD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* GPU: Graphical proessing units as the name implies were designed primarily for purposes of peocesssing graphical data on modern machines. However, GPUs have found new use in modern AI research and development as well.\n",
        "\n",
        "* TPU: GPUs equipped with tensor cores, and developed to specialize in deep learning realted tasks. Google's famous TPU available through the cloud GCP is one example."
      ],
      "metadata": {
        "id": "beBr6f1Lfu_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   GPUs are extremely well designed to possess several thousand parrallel units, and its own dedicated fast memory, however the main issue lies in the slow and tedious relationship between GPU's memory and CPU's memory, more specifically the read-write operations of the GPU to the CPU memory is very slow.\n",
        "*   Since GPU's own memory is composed of multiple levels of cache memory, which are extremely quick but also become unreliable when they rely on copies of informaiton across the different cache memories.\n",
        "* Hence why we divide the training data that is fed into some deep learning algorithm which relies on GPUs into *batches*. This allows the entire dataset to be allocated only to the GPU memory and moreover allows for parrallel computation.\n",
        "\n",
        "* A standard GPU can process upto $10^13-10^14$ flops, aka floating point operations, per second.\n",
        "\n"
      ],
      "metadata": {
        "id": "bn0ox4iRtvTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensors"
      ],
      "metadata": {
        "id": "KstGWW_zzqFZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A ***tensor*** is a mathematical object that generalizes scalars, vectors, and matrices to arbitrarily high dimensions. Formally, an order $n$ tensor over a field $\\mathbb{F}$ is an element of the tensor product of $n$ copies of an $\\mathbb{F}$-vector space $\\mathbb{V}$. This means it is a multilinear map\n",
        "\n",
        "$$T: \\mathbb{V} \\times \\dots \\times \\mathbb{V} \\rightarrow \\mathbb{F}$$\n",
        "\n",
        "That is, $T$ takes $n$ vectors $\\mathbf{v}_1, \\dots, \\mathbf{v}_n$ as input and produces a scalar $T(\\mathbf{v}_1, \\dots, \\mathbf{v}_n)$ as output. The multilinear property means that $T$ is linear in each of its arguments when the others are fixed.\n",
        "\n",
        "Some key properties of tensors:\n",
        "\n",
        "- A $0^\\text{th}$ order tensor is a scalar\n",
        "- A $1^\\text{st}$ order tensor is a vector\n",
        "- A $2^\\text{nd}$ order tensor is a matrix\n",
        "- Tensors have a rank ($n$) and dimension/shape for each mode\n",
        "- The rank determines the number of indices needed to index a tensor\n",
        "- The dimension of each mode is determined by the vector space $\\mathbb{V}$\n",
        "\n",
        "So in summary, a tensor is a multidimensional array that has linear algebraic properties generalizing scalars, vectors, and matrices. The order/rank determines the number of indices, while the shape/dimension of each mode is determined by the underlying vector space."
      ],
      "metadata": {
        "id": "e2kXm45WzxsK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The input tensors represent most often the entire network simultaneusly, i.e. the tensor as a form of database consists of the input signal, the trainable weights, and all the intermediate calculations, namley the ***acvtivation*** values, of the hidden layers.\n",
        "\n",
        "* As an example; a time series input is encoded as some $T \\times D$ tensor where $T$ is the duration or time elapsed, and $D$ is the dimension of the feature respresentation at each time step, aka the *number of channels*.\n",
        "\n",
        "* An RGB image input would correspond to $D=3$. Suppose we had $50$ RGb valued images with resolution of $32 \\times 24$, then this collection of input can be encoded as a $50 \\times 3 \\times 24 \\times 32$ tensor."
      ],
      "metadata": {
        "id": "q1i_OFIw4WyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that mathematically any computation can be decomposed into a series of elementary tensor operations. Hence why expressing our models, the input signals, and our outputs in this particular framework is so helpful in taking advantage of the computational benefits of tensor operations."
      ],
      "metadata": {
        "id": "YKPGOz786RCj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PH2Decp_O3iY"
      },
      "outputs": [],
      "source": []
    }
  ]
}