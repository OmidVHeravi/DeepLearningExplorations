{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3/p+MWywtqc2HxNYyw1Uf"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Gradient Descent"
      ],
      "metadata": {
        "id": "qnSwiW1UQqfW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Given that in most cases our trainable parameters aka the weights are not represented in math closed forms, hence in order to minimize/maximize the values of the weights, one must resort to a process known as ***Gradient Descent***.\n",
        "\n",
        "* Gradient Descent is the process of choosing some random inital weight, i.e. $w_0$, and we intend to improve the value of this weight in the direction in which it minimizes our loss, thus we iteratively improve the weight by computing the gradient/derivative of the loss/error function with respect to the trainable parameters/weight. The exact expression is:\n",
        "$$\n",
        "w_{n+1} = w_n - \\eta \\times ∇Λ_w(w_n)\n",
        "$$\n",
        "\n",
        "* This is essentially the process by which we move the value of the weights in the direction in which the error is minimized as most as possible."
      ],
      "metadata": {
        "id": "Pumn0XGfQycL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate"
      ],
      "metadata": {
        "id": "IYw9Zca9TZFB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The variable, also often the parameter $\\eta$, is known as the learning parameter. It ranges from $0$ to $1$, and it modulates the amount by which we move in the direction of the gradient.\n",
        "\n",
        "* Choosing a value too small may run the risk of the optimization getting stuck in a local minima and slowing down the optimization, and choosing a value too large will force the model to constantly get close and bounce around a good minima but never attain it."
      ],
      "metadata": {
        "id": "ASjcm_FLTcmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stochastic Gradient Descent"
      ],
      "metadata": {
        "id": "Tk6nYucgWHnF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose that our loss function has the general form:\n",
        "$$\n",
        "Λ(w) = \\frac{\\sum_{i=1}^{N} Λ_n(w)}{N}\n",
        "$$\n",
        "thus the gradient becomes:\n",
        "$$\n",
        "∇_w \\Lambda(w) = \\frac{\\sum_{i=1}^{N} ∇_w Λ_n(w)}{N}\n",
        "$$\n",
        "But computing the gradients and updating the weights in this fashion is very computationally heavy, as such we look for another alterantive method.\n",
        "\n"
      ],
      "metadata": {
        "id": "bajzBHdEWKZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead suppose we compute an estimate of the gradient is computed using only a small subset or batch of the training data. However this estimate is noisy, meaning it is not exactly equal to the true gradient, but it is an unbiased estimator, meaning that on average, it will point in the same direction as the true gradient."
      ],
      "metadata": {
        "id": "cWGmmV_gHALm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The advantage of using SGD is that it can be far more efficient than standard gradient descent. Since only a small batch of data is used to compute the gradient estimate at each iteration, the computational cost per iteration is much lower."
      ],
      "metadata": {
        "id": "O8O9IifIHybN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This means that for the same computational budget, many more iterations of SGD can be performed compared to standard gradient descent1. Additionally, due to the redundancy in the data, meaning that many training examples provide similar information, using a small batch of data can still provide a good estimate of the true gradient. As a result, SGD can often converge to a good solution much faster than standard gradient descent."
      ],
      "metadata": {
        "id": "HI5cUtVPHzUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of the most common and popular variations of the traditional SGD optimizer is the ADAM optimizer. Adam, which stands for Adaptive Moment Estimation, was proposed by Kingma and Ba in 2014. It keeps running estimates of the mean and variance of each component of the gradient and normalizes them automatically. This helps to avoid scaling issues and different training speeds in different parts of a model."
      ],
      "metadata": {
        "id": "9vvrOH6SIMTM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BackPropogation"
      ],
      "metadata": {
        "id": "55QhHJvyIvc8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gradient descent is a first-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent."
      ],
      "metadata": {
        "id": "fmF_xMUiKM7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " The loss function $Λ$ measures how well the model $F$ is able to make predictions given input $x$ and parameters $w$. Since both $F$ and $Λ$ are compositions of standard tensor operations, the chain rule from differential calculus can be used to compute the gradient."
      ],
      "metadata": {
        "id": "MZ10FYpIOhhh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\documentclass{standalone}\n",
        "\\usepackage{tikz}\n",
        "\n",
        "\\begin{document}\n",
        "\\begin{tikzpicture}[scale=1.5, transform shape]\n",
        "\n",
        "% Nodes\n",
        "\\foreach \\i in {1,...,3} {\n",
        "    \\node[draw, circle, fill=blue!20] (I\\i) at (0,\\i) {$I_{\\i}$};\n",
        "    \\node[draw, circle, fill=blue!20] (H\\i) at (2,\\i) {$H_{\\i}$};\n",
        "    \\node[draw, circle, fill=blue!20] (O\\i) at (4,\\i) {$O_{\\i}$};\n",
        "}\n",
        "\n",
        "% Forward pass arrows\n",
        "\\foreach \\i in {1,...,3} {\n",
        "    \\foreach \\j in {1,...,3} {\n",
        "        \\draw[->] (I\\i) -- (H\\j);\n",
        "        \\draw[->] (H\\i) -- (O\\j);\n",
        "    }\n",
        "}\n",
        "\n",
        "% Backward pass arrows (dotted)\n",
        "\\foreach \\i in {1,...,3} {\n",
        "    \\foreach \\j in {1,...,3} {\n",
        "        \\draw[->, dotted] (O\\j) -- (H\\i);\n",
        "        \\draw[->, dotted] (H\\j) -- (I\\i);\n",
        "    }\n",
        "}\n",
        "\n",
        "% Text\n",
        "\\node at (1,4) {Forward Pass};\n",
        "\\node at (3,4) {Backward Pass};\n",
        "\n",
        "\\end{tikzpicture}\n",
        "\\end{document}\n"
      ],
      "metadata": {
        "id": "hg9OZdnPPNP_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bTdhrJ0sQs1h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}